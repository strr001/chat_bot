from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Literal

from utils import find_best_resume_example
from translation_utils import translate_messages, translate_from_english
from llama_client import generate_llama_response, extract_text_from_string
from fastapi.staticfiles import StaticFiles
import os

app = FastAPI()

app.mount("/examples_cv", StaticFiles(directory="examples_cv"), name="examples_cv")

# –ú–æ–¥–µ–ª—ñ
class Message(BaseModel):
    role: Literal["user", "assistant"]
    content: str

class ChatRequest(BaseModel):
    messages: List[Message]
    include_example: bool = False


@app.post("/chat")
async def chat(request: ChatRequest):
    if not request.messages:
        raise HTTPException(status_code=400, detail="Empty message history")

    # –ü–µ—Ä–µ–∫–ª–∞–¥ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
    try:
        messages_en = translate_messages([msg.dict() for msg in request.messages], target_lang="EN")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Translation to English failed: {str(e)}")

    # –Ø–∫—â–æ –∑–∞–ø–∏—Ç–∞–Ω–æ –ø—Ä–∏–∫–ª–∞–¥ —Ä–µ–∑—é–º–µ ‚Äî —Ç—ñ–ª—å–∫–∏ –ø—Ä–∏–∫–ª–∞–¥ + –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
    if request.include_example:
        user_message_en = messages_en[-1]["content"]
        example = find_best_resume_example(user_message_en)

        response = {
            "response": "üîç –ü–æ –≤–∞—à–æ–º—É –∑–∞–ø–∏—Ç—É —è –∑–Ω–∞–π—à–æ–≤ –ø—Ä–∏–∫–ª–∞–¥ —Ä–µ–∑—é–º–µ. –û–∑–Ω–∞–π–æ–º—Ç–µ—Å—å —ñ–∑ –Ω–∏–º –Ω–∏–∂—á–µ."
        }

        if example:
            response["example_filename"] = example["filename"]
            response["example_title"] = example["title"]
            response["example_url"] = f"/examples_cv/{example['filename']}"
        else:
            response["response"] =  ("üîç –ü–æ –≤–∞—à–æ–º—É –∑–∞–ø–∏—Ç—É —è –Ω–µ –∑–Ω–∞–π—à–æ–≤ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏—Ö —Ä–µ–∑—é–º–µ. –ë—É–¥—å –ª–∞—Å–∫–∞, "
                                     "–≤–∫–∞–∂—ñ—Ç—å —Ç–æ—á–Ω—ñ—à–µ —Ç—É —Å–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ—Å—Ç—å –∞–±–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—é, –∑–≥—ñ–¥–Ω–æ —è–∫–∏—Ö –ø–æ—Ç—Ä—ñ–±–Ω–æ "
                                     "–Ω–∞–¥–∞—Ç–∏ —Ä–µ–∞–ª—å–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥ —Ä–µ–∑—é–º–µ. –¢–∞–∫–æ–∂ —Å–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–¥–∞—Ç–∏ –∑–∞–ø–∏—Ç –º–µ–Ω—ñ –Ω–∞–ø—Ä—è–º—É "
                                     "(–±–∞–∂–∞–Ω–æ –ø–æ–µ—Ç–∞–ø–Ω–æ), —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—è –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –≤–∞–º –≥–∞—Ä–Ω–µ —Ä–µ–∑—é–º–µ ü§ó.")

        return response

    # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    try:
        assistant_reply_en = generate_llama_response(messages_en)
        assistant_reply_en = extract_text_from_string(assistant_reply_en)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"LLaMA response failed: {str(e)}")

    try:
        assistant_reply_ua = translate_from_english(assistant_reply_en, target_lang="UK")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Translation to Ukrainian failed: {str(e)}")

    return {"response": assistant_reply_ua}
